{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5437be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and create client\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-4-5-sonnet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0d8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_user_message(messages, text):\n",
    "    user_message = {\"role\": \"user\", \"content\": text}\n",
    "    messages.append(user_message)\n",
    "\n",
    "\n",
    "def add_assistant_message(messages, text):\n",
    "    assistant_message = {\"role\": \"assistant\", \"content\": text}\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e788701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a new dataset\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "        \"format\": \"json\" or \"python\" or \"regex\"\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "438ed743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset and write it to 'dataset.json'\n",
    "dataset = generate_dataset()\n",
    "with open(\"dataset2.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b89174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grade a test case + output using a model\n",
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Output Format\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths\n",
    "- \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "- \"reasoning\": A concise explanation of your overall assessment\n",
    "- \"score\": A number between 1-10\n",
    "\n",
    "Respond with JSON. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": string[],\n",
    "    \"weaknesses\": string[],\n",
    "    \"reasoning\": string,\n",
    "    \"score\": number\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, eval_prompt)\n",
    "    add_assistant_message(messages, \"```json\")\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83809a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passes a test case into Claude\n",
    "def run_prompt(test_case):\n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case[\"task\"]}\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_user_message(messages, prompt)\n",
    "    output = chat(messages)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bcc4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a single test case and grade the output\n",
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fa99d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30fae983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 7.333333333333333\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset2.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbcc6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"output\": \"I'll create a regular expression that validates AWS S3 bucket names according to all the specified rules.\\n\\n```regex\\n^(?!.*\\\\.\\\\.)(?!.*\\\\.$)(?!^\\\\.)([a-z0-9])([a-z0-9.-]{1,61})([a-z0-9])$\\n```\\n\\n**Explanation of the regex components:**\\n\\n1. `^` - Start of string\\n2. `(?!.*\\\\.\\\\.)` - Negative lookahead: no consecutive periods anywhere\\n3. `(?!.*\\\\.$)` - Negative lookahead: doesn't end with a period\\n4. `(?!^\\\\.)` - Negative lookahead: doesn't start with a period\\n5. `([a-z0-9])` - Must start with a lowercase letter or number (1 character)\\n6. `([a-z0-9.-]{1,61})` - Middle characters: lowercase letters, numbers, hyphens, or periods (1-61 characters)\\n7. `([a-z0-9])` - Must end with a lowercase letter or number (1 character)\\n8. `$` - End of string\\n\\nThis ensures:\\n- **Total length: 3-63 characters** (1 + 1-61 + 1 = 3-63)\\n- **Only lowercase letters, numbers, hyphens, and periods**\\n- **Starts with a letter or number**\\n- **Ends with a letter or number**\\n- **No consecutive periods**\\n\\n**Test examples:**\\n\\n\\u2705 Valid:\\n- `my-bucket-123`\\n- `example.bucket`\\n- `test-bucket.name`\\n- `abc`\\n- `a1b2c3`\\n\\n\\u274c Invalid:\\n- `My-Bucket` (uppercase)\\n- `-bucket` (starts with hyphen)\\n- `bucket-` (ends with hyphen)\\n- `my..bucket` (consecutive periods)\\n- `ab` (too short)\\n- `.bucket` (starts with period)\\n- `bucket.` (ends with period)\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a regular expression that validates AWS S3 bucket names according to AWS naming rules: 3-63 characters long, only lowercase letters, numbers, hyphens, and periods, must start and end with a letter or number, and cannot have consecutive periods.\",\n",
      "      \"format\": \"regex\"\n",
      "    },\n",
      "    \"score\": 6,\n",
      "    \"reasoning\": \"The solution demonstrates strong understanding of regex patterns and AWS S3 naming rules, with good documentation. However, there's a critical logic error in handling the minimum length constraint - the regex doesn't properly validate 3-character names. The pattern requires 1 start + 1-61 middle + 1 end, but for a 3-character name like 'abc', the middle 'b' must satisfy the middle pattern while being a single distinct character. Additionally, missing the IP address validation is a notable omission from AWS requirements. Despite these issues, the core approach is sound.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"Here's a Python function that filters AWS EC2 instances by their running state:\\n\\n```python\\ndef get_running_instances(instances):\\n    \\\"\\\"\\\"\\n    Filter EC2 instances to return only those in 'running' state.\\n    \\n    Args:\\n        instances (list): List of dictionaries containing EC2 instance information.\\n                         Each dictionary should have 'InstanceId', 'State', and 'InstanceType' keys.\\n    \\n    Returns:\\n        list: List of dictionaries containing only running instances.\\n    \\n    Example:\\n        >>> instances = [\\n        ...     {'InstanceId': 'i-1234567890abcdef0', 'State': 'running', 'InstanceType': 't2.micro'},\\n        ...     {'InstanceId': 'i-0987654321fedcba0', 'State': 'stopped', 'InstanceType': 't2.small'},\\n        ...     {'InstanceId': 'i-abcdef1234567890a', 'State': 'running', 'InstanceType': 't3.medium'}\\n        ... ]\\n        >>> running = get_running_instances(instances)\\n        >>> len(running)\\n        2\\n    \\\"\\\"\\\"\\n    return [instance for instance in instances if instance.get('State') == 'running']\\n```\\n\\n**Alternative implementation using `filter()`:**\\n\\n```python\\ndef get_running_instances(instances):\\n    \\\"\\\"\\\"\\n    Filter EC2 instances to return only those in 'running' state.\\n    \\n    Args:\\n        instances (list): List of dictionaries containing EC2 instance information.\\n    \\n    Returns:\\n        list: List of dictionaries containing only running instances.\\n    \\\"\\\"\\\"\\n    return list(filter(lambda instance: instance.get('State') == 'running', instances))\\n```\\n\\n**Usage example:**\\n\\n```python\\n# Sample EC2 instances data\\nec2_instances = [\\n    {'InstanceId': 'i-1234567890abcdef0', 'State': 'running', 'InstanceType': 't2.micro'},\\n    {'InstanceId': 'i-0987654321fedcba0', 'State': 'stopped', 'InstanceType': 't2.small'},\\n    {'InstanceId': 'i-abcdef1234567890a', 'State': 'running', 'InstanceType': 't3.medium'},\\n    {'InstanceId': 'i-1111222233334444b', 'State': 'terminated', 'InstanceType': 't2.nano'},\\n    {'InstanceId': 'i-5555666677778888c', 'State': 'running', 'InstanceType': 't3.large'}\\n]\\n\\n# Get only running instances\\nrunning_instances = get_running_instances(ec2_instances)\\n\\nprint(f\\\"Total instances: {len(ec2_instances)}\\\")\\nprint(f\\\"Running instances: {len(running_instances)}\\\")\\nprint(\\\"\\\\nRunning instances details:\\\")\\nfor instance in running_instances:\\n    print(f\\\"  - {instance['InstanceId']} ({instance['InstanceType']})\\\")\\n```\\n\\n**Output:**\\n```\\nTotal instances: 5\\nRunning instances: 3\\n\\nRunning instances details:\\n  - i-1234567890abcdef0 (t2.micro)\\n  - i-abcdef1234567890a (t3.medium)\\n  - i-5555666677778888c (t3.large)\\n```\\n\\nThe function uses a list comprehension to iterate through the instances and filter only those with a 'State' value of 'running'. The `get()` method is used for safe dictionary access in case the 'State' key is missing from any instance dictionary.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a Python function that takes a list of AWS EC2 instance dictionaries (each with 'InstanceId', 'State', and 'InstanceType' keys) and returns only the instances that are in 'running' state.\",\n",
      "      \"format\": \"python\"\n",
      "    },\n",
      "    \"score\": 7,\n",
      "    \"reasoning\": \"The solution correctly implements the specified task with clean, readable code and good documentation. However, it oversimplifies the AWS EC2 state structure. In real AWS API responses, the State field is a dictionary with 'Name' and 'Code' keys, not a string. While the solution works for the task as written, it wouldn't work with actual boto3 describe_instances() output without modification. The code would benefit from basic input validation and error handling for production readiness.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"```json\\n{\\n  \\\"Version\\\": \\\"2012-10-17\\\",\\n  \\\"Statement\\\": [\\n    {\\n      \\\"Sid\\\": \\\"ListBucketContents\\\",\\n      \\\"Effect\\\": \\\"Allow\\\",\\n      \\\"Action\\\": [\\n        \\\"s3:ListBucket\\\",\\n        \\\"s3:GetBucketLocation\\\"\\n      ],\\n      \\\"Resource\\\": \\\"arn:aws:s3:::my-data-bucket\\\"\\n    },\\n    {\\n      \\\"Sid\\\": \\\"ReadObjectContents\\\",\\n      \\\"Effect\\\": \\\"Allow\\\",\\n      \\\"Action\\\": [\\n        \\\"s3:GetObject\\\",\\n        \\\"s3:GetObjectVersion\\\"\\n      ],\\n      \\\"Resource\\\": \\\"arn:aws:s3:::my-data-bucket/*\\\"\\n    }\\n  ]\\n}\\n```\\n\\nThis IAM policy provides read-only access to the S3 bucket named `my-data-bucket` with the following permissions:\\n\\n**First Statement (Bucket-level):**\\n- `s3:ListBucket` - Allows listing objects in the bucket\\n- `s3:GetBucketLocation` - Allows getting the bucket's region\\n\\n**Second Statement (Object-level):**\\n- `s3:GetObject` - Allows reading/downloading object contents\\n- `s3:GetObjectVersion` - Allows reading specific versions of objects (useful if versioning is enabled)\\n\\nThe policy uses two separate statements because bucket-level operations require the bucket ARN (`arn:aws:s3:::my-data-bucket`), while object-level operations require the object ARN pattern (`arn:aws:s3:::my-data-bucket/*`).\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Generate a JSON object representing an AWS IAM policy that allows read-only access to a specific S3 bucket named 'my-data-bucket', including permissions to list objects and get object contents.\",\n",
      "      \"format\": \"json\"\n",
      "    },\n",
      "    \"score\": 9,\n",
      "    \"reasoning\": \"The solution correctly implements a functional read-only IAM policy with proper structure, appropriate resource ARNs, and necessary permissions. The core requirements (list objects and get object contents) are fully satisfied. The included additional permissions (GetObjectVersion, GetBucketLocation) are reasonable for a production read-only policy, though slightly broader than the minimum required. The explanation is clear and accurate. This is a solid, production-ready solution with minor room for optimization based on specific use case needs.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
